# Chat Agent Module Contract

## Overview
The Chat Agent handles user interactions, retrieves relevant legal information, and generates responses using Groq LLM.

## Interface

### ChatService

```python
from abc import ABC, abstractmethod
from typing import List, Optional, AsyncIterator
from pydantic import BaseModel

class ChatConfig(BaseModel):
    model: str = "llama-3.3-70b-versatile"
    temperature: float = 0.3
    max_tokens: int = 4096
    top_k_retrieval: int = 5

class Citation(BaseModel):
    article_id: str
    article_number: int
    document_title: str
    relevance_score: float
    excerpt: str

class ChatResponse(BaseModel):
    answer: str
    citations: List[Citation]
    suggested_templates: List[str]
    follow_up_questions: List[str]

class ChatService(ABC):
    @abstractmethod
    async def chat(
        self,
        query: str,
        session_id: Optional[str] = None,
        config: Optional[ChatConfig] = None
    ) -> ChatResponse:
        """
        Process user query and return response with citations.

        1. Retrieve relevant articles from knowledge base
        2. Build RAG context
        3. Generate response via Groq LLM
        4. Extract citations and suggestions
        """
        pass

    @abstractmethod
    async def stream_chat(
        self,
        query: str,
        session_id: Optional[str] = None
    ) -> AsyncIterator[str]:
        """
        Stream response tokens for real-time display.
        """
        pass

    @abstractmethod
    def get_session_context(self, session_id: str) -> dict:
        """
        Get collected context from chat session.
        Used for document generation.
        """
        pass
```

## CLI Contract

```bash
# Interactive chat
legal-chatbot chat "Äiá»u kiá»‡n cho thuÃª nhÃ  lÃ  gÃ¬?"

# Output: Formatted response
â•­â”€ Legal Assistant â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Theo quy Ä‘á»‹nh phÃ¡p luáº­t, Ä‘iá»u kiá»‡n cho thuÃª nhÃ  bao gá»“m:  â”‚
â”‚                                                            â”‚
â”‚ 1. NgÆ°á»i cho thuÃª pháº£i lÃ  chá»§ sá»Ÿ há»¯u há»£p phÃ¡p...          â”‚
â”‚ 2. NhÃ  á»Ÿ pháº£i Ä‘áº£m báº£o cháº¥t lÆ°á»£ng...                       â”‚
â”‚                                                            â”‚
â”‚ ğŸ“š Nguá»“n:                                                  â”‚
â”‚ - Äiá»u 121, Luáº­t NhÃ  á»Ÿ 2014                               â”‚
â”‚ - Äiá»u 472, Bá»™ luáº­t DÃ¢n sá»± 2015                           â”‚
â”‚                                                            â”‚
â”‚ ğŸ“ Báº¡n cÃ³ muá»‘n táº¡o há»£p Ä‘á»“ng thuÃª nhÃ  khÃ´ng?               â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

# JSON output mode
legal-chatbot chat "Äiá»u kiá»‡n cho thuÃª nhÃ ?" --json
{
  "answer": "...",
  "citations": [...],
  "suggested_templates": ["rental"]
}
```

## RAG Pipeline

```
User Query
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Query Analysis  â”‚ â†’ Intent, entities, legal domain
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vector Search   â”‚ â†’ ChromaDB semantic search
â”‚ (top-k=5)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Context Builder â”‚ â†’ Format retrieved articles
â”‚                 â”‚ â†’ Apply token limit
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Groq LLM        â”‚ â†’ Generate grounded response
â”‚                 â”‚ â†’ Include citations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Post-process    â”‚ â†’ Extract citations
â”‚                 â”‚ â†’ Suggest templates
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## System Prompt Template

```python
SYSTEM_PROMPT = """
Báº¡n lÃ  trá»£ lÃ½ phÃ¡p lÃ½ cá»§a má»™t cÃ´ng ty luáº­t Viá»‡t Nam.
Nhiá»‡m vá»¥ cá»§a báº¡n lÃ :

1. Tráº£ lá»i cÃ¢u há»i phÃ¡p lÃ½ dá»±a HOÃ€N TOÃ€N vÃ o cÃ¡c Ä‘iá»u luáº­t Ä‘Æ°á»£c cung cáº¥p
2. LUÃ”N trÃ­ch dáº«n nguá»“n (sá»‘ Äiá»u, tÃªn vÄƒn báº£n phÃ¡p luáº­t)
3. Náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan, nÃ³i rÃµ "TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin"
4. Äá» xuáº¥t máº«u há»£p Ä‘á»“ng náº¿u phÃ¹ há»£p vá»›i cÃ¢u há»i

CÃ¡c Ä‘iá»u luáº­t liÃªn quan:
{context}

LÆ°u Ã½: ÄÃ¢y chá»‰ lÃ  thÃ´ng tin tham kháº£o, khÃ´ng thay tháº¿ tÆ° váº¥n phÃ¡p lÃ½ chuyÃªn nghiá»‡p.
"""
```

## Dependencies
- groq: Groq API client
- chromadb: Vector retrieval

## Testing Contract

```python
async def test_chat_returns_citations():
    """Chat should include relevant citations"""
    response = await chat_service.chat("Äiá»u kiá»‡n cho thuÃª nhÃ ?")
    assert response.citations
    assert all(c.article_number for c in response.citations)

async def test_chat_grounds_in_context():
    """Chat should only use information from retrieved context"""
    # Mock retrieval to return specific articles
    # Verify response only contains info from those articles
```
